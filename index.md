---
layout: default
---

## About Me

<img class="profile-picture" src="AIS_square.jpeg">

I am a last-year PhD candidate in the Stanford AI Lab, interested in robot learning, perception, and controls. 

**Email:** michellelee@cs.stanford.edu

**Twitter:** [michellearning](https://twitter.com/michellearning)

Gates Computer Science Building, Room 132 <br>
353 Serra Mall, Stanford University<br>
Stanford, CA 94305-9025, USA<br>

## Recent News

* [March 2021] Invited Talk at NYU CS Colloquium 
* [March 2021] Invited Talk as Distinguished Lecturer at UT Austin CS Department
* [March 2021] One paper submitted to IROS 2021
* [March 2021] Two paper accepted in ICRA 2021 
* [March 2021] Invited Talk at UPenn MEAM Seminar
* [January 2021] Invited Talk at Google Robotics 
* [December 2020] Invited Talk at NVIDIA Research 
* [December 2020] I was invited to speak on the panel at the NeurIPS 2020 [Object Representatons for Learning and Reasoning Workshop](https://orlrworkshop.github.io/index.html)



## Invited Talks

* NeurIPS 2020 Object Representations for Learning and Reasoning Workshop, Panel Discussion, December 11, 2020

* NVIDIA GTC 2020, “Deep Dive with Michelle A. Lee, Making Sense of Vision and Touch: Self- Supervised Learning of Multimodal Representations for Contact-Rich Tasks (ICRA),” May 14, 2020

* National Cheng Kung University Institute of Manufacturing Information and Systems Seminar Talk, “Multimodal Fusion for Robust Learning,” May 7, 2020

* Stanford Computer Science Faculty Lunch Ph.D. Student Presentation, “Making Sense of Vision and Touch: Combining Sensor Modalities for Robust Robot Learning,” March 17, 2020

* NeurIPS 2019 Workshop on Robot Learning: Control and Interaction in the Real World, “Best Paper Invited Talk: Guided Uncertainty-Aware Policy Optimization,” December 14, 2019


## Publications
1. **Making sense of vision and touch: Self-supervised learning of multimodal representations for contact-rich tasks** 
    
    Michelle A. Lee\*, Yuke Zhu\*, Krishnan Srinivasan, Parth Shah, Silvio Savarese, Li Fei-Fei, Animesh Garg, Jeannette Bohg 

    _IEEE International Conference on Robotics and Automation (ICRA), May 2019_

    <span style="color:blue">Best Paper Award in ICRA 2019 </span>

    <span style="color:blue">Finalist for Best Paper in Cognitive Robotics in ICRA 2019</span>.

    [[Paper]](https://arxiv.org/abs/1810.10191) [[Website]](https://sites.google.com/view/visionandtouch) [[Video]](https://www.youtube.com/watch?v=usFQ8hNtE8c&feature=emb_title) [[Code and Dataset]](https://github.com/stanford-iprl-lab/multimodal_representation/)

2. **Variable Impedance Control in End-Effector Space:
An Action Space for Reinforcement Learning in Contact-Rich Tasks**

    Roberto Martín-Martín, Michelle A. Lee, Rachel Gardner, Silvio Savarese, Jeannette Bohg, Animesh Garg

    _IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), November 2019_

    [[Paper]](https://arxiv.org/abs/1906.08880) [[Website]](https://stanfordvl.github.io/vices/) [[Video]](https://www.youtube.com/watch?v=AozIUIW3Ghs&feature=youtu.be)

3. **Making sense of vision and touch: Learning multimodal representations for contact-rich tasks**
    
     Michelle A. Lee, Yuke Zhu, Peter Zachares, Matthew Tan, Krishnan Srinivasan, Silvio Savarese, Li Fei-Fei, Animesh Garg, Jeannette Bohg

     _IEEE Transactions on Robotics, March 2020_

    [[Paper]](http://ieeexplore.ieee.org/document/9043710) [[Code and Dataset]](https://github.com/stanford-iprl-lab/multimodal_representation/)

4. **Guided Uncertainty Aware Policy Optimization: Combining Learning and Model-Based Strategies for Sample-Efficient Policy Learning**
    
    Michelle A. Lee\*, Carlos Florensa\*, Jonathan Tremblay, Nathan Ratliff, Animesh Garg, Fabio Ramos,  and Dieter Fox 

     _IEEE International Conference on Robotics and Automation (ICRA), May 2020_ 

     <span style="color:blue">Best Paper Award at the NeurIPS Robot Learning Workshop 2019 </span>

    
    [[Paper]]() [[Website]](https://sites.google.com/view/guapo-rl) [[Video]](https://www.youtube.com/watch?v=_RGBMdiSMgw)

5. **Multimodal Sensor Fusion with Differentiable Filters**
    
    Michelle A. Lee\*, Brent Yi\*, Roberto Martín-Martín, Silvio Savarese, Jeannette Bohg
     
    _IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), October 2020_

    [[Paper]](https://arxiv.org/abs/2010.13021) [[Website]](https://sites.google.com/view/multimodalfilter) [[Code]](https://github.com/brentyi/multimodalfilter)

6. **Detect, Reject, Correct: Crossmodal Compensation of Corrupted Sensors**
    
    Michelle A. Lee, Matthew Tan, Yuke Zhu, Jeannette Bohg

    _IEEE International Conference on Robotics and Automation (ICRA), June 2021_

    

    [[Paper]](https://arxiv.org/abs/2012.00201) [[Website]](https://sites.google.com/view/crossmodal-compensation/)


7. **Interpreting Contact Interactions to Overcome Failure in Robot Assembly Tasks**

    Peter A. Zachares, Michelle A. Lee, Wenzhao Lian, Jeannette Bohg

    _IEEE International Conference on Robotics and Automation (ICRA), June 2021_

    [[Paper]](https://arxiv.org/abs/2101.02725)

8. **Differentiable Factor Graph Optimization for Learning Smoothers**

    Brent Yi, Michelle A. Lee, Alina Kloss, Roberto Martín-Martín, Jeannette Bohg

    Submitted to IROS 2021 

## Teaching

* [2019] Stanford CS336: Robot Perception and Decision-Making, teaching assistant
* [2018] Stanford AI4All Research Mentor
* [2017] Stanford CS326:Topics in Advanced Robotic Manipulation, teaching assistant





